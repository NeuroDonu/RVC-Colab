{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Google Colab запретил пользовательский интерфейс Gradio для бесплатных пользователей, но вы все равно можете использовать RVC. Обучение пока ТОЛЬКО, скоро добавлю Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Установка на Гугл Диск (Для автоматической тренировки и сохранения прогресса.)\n",
    "from google.colab import drive\n",
    "from IPython.utils import capture\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "\n",
    "%cd /content/\n",
    "drive.mount('/content/drive')\n",
    "if not os.path.exists('/content/drive'):\n",
    "    print(\"Ты не смонтировал свой диск. Сделаем фейк!\")\n",
    "    os.makedirs('/content/drive/MyDrive')\n",
    "else:\n",
    "    print(\"Молодец! Продолжаем.\")\n",
    "with capture.capture_output() as cap:\n",
    "    def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
    "    !wget https://huggingface.co/NeuroDonu/rvc/resolve/main/project-main.zip \n",
    "    !unzip -n 'project-main.zip' -d /content/drive/MyDrive\n",
    "    %cd /content/drive/MyDrive/project-main\n",
    "    !python download_files.py \n",
    "    %pip install -r requirements-safe.txt\n",
    "    !rm /content/project-main.zip\n",
    "    !rm -r /content/sample_data\n",
    "    !mkdir -p /content/dataset\n",
    "clear_output()\n",
    "inf('\\u2714 Готово','success', '50px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 1.Препроцесс данных\n",
    "from IPython.utils import capture\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
    "%cd /content/drive/MyDrive/project-main\n",
    "model_name = 'My-Voice' #@param {type:\"string\"}\n",
    "#@markdown <small> Вставь сюда путь к своему датасету, либо открой проводник тут и загрузи папку с названием 'dataset'.\n",
    "dataset_folder = '/content/dataset' #@param {type:\"string\"}\n",
    "while len(os.listdir(dataset_folder)) < 1:\n",
    "    input(\"Твой датасет пустой!.\")\n",
    "!mkdir -p ./logs/{model_name}\n",
    "with open(f'./logs/{model_name}/preprocess.log','w') as f:\n",
    "    print(\"Начинаю...\")\n",
    "!python infer/modules/train/preprocess.py {dataset_folder} 40000 2 ./logs/{model_name} False 3.0 > /dev/null 2>&1\n",
    "with open(f'./logs/{model_name}/preprocess.log','r') as f:\n",
    "    if 'end preprocess' in f.read():\n",
    "        clear_output()\n",
    "        inf('\\u2714 Готово','success', '50px')\n",
    "    else:\n",
    "        print(\"Ошибка препроцесса... Сделай корректный датасет.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 2.Извлечение\n",
    "f0method = \"rmvpe_gpu\" # @param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
    "%cd /content/drive/MyDrive/project-main\n",
    "with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n",
    "    print(\"Starting...\")\n",
    "if f0method != \"rmvpe_gpu\":\n",
    "    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n",
    "else:\n",
    "    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} True\n",
    "!python infer/modules/train/extract_feature_print.py cuda:0 1 0 0 ./logs/{model_name} v2\n",
    "with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n",
    "    if 'all-feature-done' in f.read():\n",
    "        clear_output()\n",
    "        inf('\\u2714 Готово','success', '50px')\n",
    "    else:\n",
    "        print(\"Ошибка препроцесса...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 3.Тренировка индекса\n",
    "import numpy as np\n",
    "import faiss\n",
    "%cd /content/drive/MyDrive/project-main\n",
    "def train_index(exp_dir1, version19):\n",
    "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    feature_dir = (\n",
    "        \"%s/3_feature256\" % (exp_dir)\n",
    "        if version19 == \"v1\"\n",
    "        else \"%s/3_feature768\" % (exp_dir)\n",
    "    )\n",
    "    if not os.path.exists(feature_dir):\n",
    "        return \"请先进行特征提取!\"\n",
    "    listdir_res = list(os.listdir(feature_dir))\n",
    "    if len(listdir_res) == 0:\n",
    "        return \"请先进行特征提取！\"\n",
    "    infos = []\n",
    "    npys = []\n",
    "    for name in sorted(listdir_res):\n",
    "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
    "        npys.append(phone)\n",
    "    big_npy = np.concatenate(npys, 0)\n",
    "    big_npy_idx = np.arange(big_npy.shape[0])\n",
    "    np.random.shuffle(big_npy_idx)\n",
    "    big_npy = big_npy[big_npy_idx]\n",
    "    if big_npy.shape[0] > 2e5:\n",
    "        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
    "        yield \"\\n\".join(infos)\n",
    "        try:\n",
    "            big_npy = (\n",
    "                MiniBatchKMeans(\n",
    "                    n_clusters=10000,\n",
    "                    verbose=True,\n",
    "                    batch_size=256 * config.n_cpu,\n",
    "                    compute_labels=False,\n",
    "                    init=\"random\",\n",
    "                )\n",
    "                .fit(big_npy)\n",
    "                .cluster_centers_\n",
    "            )\n",
    "        except:\n",
    "            info = traceback.format_exc()\n",
    "            logger.info(info)\n",
    "            infos.append(info)\n",
    "            yield \"\\n\".join(infos)\n",
    "\n",
    "    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
    "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
    "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
    "    yield \"\\n\".join(infos)\n",
    "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
    "    infos.append(\"training\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    index_ivf = faiss.extract_index_ivf(index)  #\n",
    "    index_ivf.nprobe = 1\n",
    "    index.train(big_npy)\n",
    "    faiss.write_index(\n",
    "        index,\n",
    "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
    "    )\n",
    "\n",
    "    infos.append(\"adding\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    batch_size_add = 8192\n",
    "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
    "        index.add(big_npy[i : i + batch_size_add])\n",
    "    faiss.write_index(\n",
    "        index,\n",
    "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
    "    )\n",
    "    infos.append(\n",
    "        \"成功构建索引，added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
    "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "\n",
    "training_log = train_index(model_name, 'v2')\n",
    "\n",
    "for line in training_log:\n",
    "    print(line)\n",
    "    if 'adding' in line:\n",
    "        clear_output()\n",
    "        inf('\\u2714 Готово','success', '50px')\n",
    "    else:\n",
    "        print(\"Ошибка! Твой индекс не получился\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 4.Тренировка модели\n",
    "%cd /content/drive/MyDrive/project-main\n",
    "from random import shuffle\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "now_dir=os.getcwd()\n",
    "#@markdown <small> Введите название вашей модели еще раз. Это должно быть то же самое, что вы выбрали раньше.\n",
    "model_name = 'My-Voice'#@param {type:\"string\"}\n",
    "#@markdown <small> Выберите, как часто сохранять модель и сколько времени вы хотите для ее обучения.\n",
    "save_frequency = 20 # @param {type:\"slider\", min:5, max:50, step:5}\n",
    "epochs = 300 # @param {type:\"slider\", min:10, max:1000, step:10}\n",
    "#@markdown <small> Кэшируются ТОЛЬКО наборы данных продолжительностью менее 10 минут. В противном случае оставьте это без флажка.\n",
    "cache = True #@param {type:\"boolean\"}\n",
    "\n",
    "def click_train(\n",
    "    exp_dir1,\n",
    "    sr2,\n",
    "    if_f0_3,\n",
    "    spk_id5,\n",
    "    save_epoch10,\n",
    "    total_epoch11,\n",
    "    batch_size12,\n",
    "    if_save_latest13,\n",
    "    pretrained_G14,\n",
    "    pretrained_D15,\n",
    "    gpus16,\n",
    "    if_cache_gpu17,\n",
    "    if_save_every_weights18,\n",
    "    version19,\n",
    "):\n",
    "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
    "    feature_dir = (\n",
    "        \"%s/3_feature256\" % (exp_dir)\n",
    "        if version19 == \"v1\"\n",
    "        else \"%s/3_feature768\" % (exp_dir)\n",
    "    )\n",
    "    if if_f0_3:\n",
    "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
    "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
    "        names = (\n",
    "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
    "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
    "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
    "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
    "        )\n",
    "    else:\n",
    "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
    "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
    "        )\n",
    "    opt = []\n",
    "    for name in names:\n",
    "        if if_f0_3:\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
    "                % (\n",
    "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "                    name,\n",
    "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "                    name,\n",
    "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "                    name,\n",
    "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "                    name,\n",
    "                    spk_id5,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
    "                % (\n",
    "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "                    name,\n",
    "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "                    name,\n",
    "                    spk_id5,\n",
    "                )\n",
    "            )\n",
    "    fea_dim = 256 if version19 == \"v1\" else 768\n",
    "    if if_f0_3:\n",
    "        for _ in range(2):\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
    "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
    "            )\n",
    "    else:\n",
    "        for _ in range(2):\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
    "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
    "            )\n",
    "    shuffle(opt)\n",
    "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
    "        f.write(\"\\n\".join(opt))\n",
    "\n",
    "    print(\"Готово\")\n",
    "    print(\"Использую видеокарту:\", str(gpus16))\n",
    "    if pretrained_G14 == \"\":\n",
    "        print(\"Нет предварительно обученного генератора\")\n",
    "    if pretrained_D15 == \"\":\n",
    "        print(\"Нет предварительно обученного дискриминатора\")\n",
    "    if version19 == \"v2\" or sr2 == \"40k\":\n",
    "        config_path = \"configs/v2/%s.json\" % sr2\n",
    "    else:\n",
    "        config_path = \"configs/v1/%s.json\" % sr2\n",
    "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
    "    if not pathlib.Path(config_save_path).exists():\n",
    "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            with open(config_path, \"r\") as config_file:\n",
    "                config_data = json.load(config_file)\n",
    "                json.dump(\n",
    "                    config_data,\n",
    "                    f,\n",
    "                    ensure_ascii=False,\n",
    "                    indent=4,\n",
    "                    sort_keys=True,\n",
    "                )\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    cmd = (\n",
    "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
    "        % (\n",
    "            exp_dir1,\n",
    "            sr2,\n",
    "            1 if if_f0_3 else 0,\n",
    "            batch_size12,\n",
    "            gpus16,\n",
    "            total_epoch11,\n",
    "            save_epoch10,\n",
    "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
    "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
    "            1 if if_save_latest13 == True else 0,\n",
    "            1 if if_cache_gpu17 == True else 0,\n",
    "            1 if if_save_every_weights18 == True else 0,\n",
    "            version19,\n",
    "        )\n",
    "    )\n",
    "    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
    "\n",
    "    for line in p.stdout:\n",
    "        print(line.strip())\n",
    "\n",
    "    p.wait()\n",
    "    return \"训练结束, 您可查看控制台训练日志或实验文件夹下的train.log\"\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs\n",
    "training_log = click_train(\n",
    "    model_name,\n",
    "    '40k',\n",
    "    True,\n",
    "    0,\n",
    "    save_frequency,\n",
    "    epochs,\n",
    "    7,\n",
    "    True,\n",
    "    'assets/pretrained_v2/f0G40k.pth',\n",
    "    'assets/pretrained_v2/f0D40k.pth',\n",
    "    0,\n",
    "    cache,\n",
    "    True,\n",
    "    'v2',\n",
    ")\n",
    "print(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Либо включаем GUI (Он забанен для пользователей без подписки)\n",
    "if not 'installed' in locals():\n",
    "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)/n\n",
    "    %cd /content/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    from IPython.display import clear_output\n",
    "    import ipywidgets as widgets\n",
    "    import os\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        print(\"Твой диск не смонтирован. Создание фейка.\")\n",
    "        os.makedirs('/content/drive/MyDrive')\n",
    "    if not os.path.exists('/content/drive/MyDrive/project-main'):\n",
    "        !wget https://huggingface.co/Rejekts/project/resolve/main/project-main.zip -O '/content/project-main.zip' && unzip 'project-main.zip' -d /content/drive/MyDrive\n",
    "    !cd '/content/drive/MyDrive/project-main' && python download_files.py && pip install -r 'requirements.txt'\n",
    "    !rm /content/project-main.zip\n",
    "    !rm -r /content/sample_data\n",
    "    !mkdir -p /content/dataset\n",
    "    clear_output()\n",
    "    inf('\\u2714 Готово','success', '50px')\n",
    "tensorboard = True #@param {type:\"boolean\"}\n",
    "if tensorboard:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir ./logs\n",
    "%cd /content/drive/MyDrive/project-main\n",
    "!python app.py --colab"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
